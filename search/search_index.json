{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"posts/","title":"Posts","text":""},{"location":"posts/2019/08/01/accessibility-constraint-mapping/","title":"Accessibility constraint mapping","text":"<p>Off-road navigation often involves difficult-to-traverse terrain or barriers, such as stairs, sidewalk curbs, construction sites, uneven pavement, etc. Global navigation planning provided by traditional mapping software (e.g. Google maps, Waze) does not typically account for such constraints, and may not be able to plan for unforeseen constraints that vary on a day-to-day basis such as temporary obstacles or path deteriorations. This project seeks to optimize path planning in light of variable off-road navigation constraints by building navigation maps in real-time using simultaneous localization and mapping (SLAM) software. Potential end-users of off-road navigation maps include autonomous rovers and handicapped persons.</p> <p></p> <p>Fig 1. Overview of the accessibility constraint mapping framework.</p>"},{"location":"posts/2019/08/01/accessibility-constraint-mapping/#links","title":"Links","text":"<ul> <li>Code repository \u2014 robotic operating system (ROS) package and computer vision scripts</li> </ul>"},{"location":"posts/2019/08/01/accessibility-constraint-mapping/#project-highlights","title":"Project highlights","text":"<p>Fig 2. An example off-road navigation map using Google maps.</p> <ul> <li>ZED camera real-time video feed for mapping off-road paths on Virginia Tech's campus</li> <li>Image processing with the <code>opencv</code> Python wrapper library</li> <li>Real-time object detection with the YOLOv3 neural network</li> <li>Integration with robotic operating system (ROS) and localization of objects with SLAM-based software</li> <li>Occupancy grid generation with off-road navigation constraints</li> </ul>"},{"location":"posts/2019/08/01/accessibility-constraint-mapping/#contributions","title":"Contributions","text":"<ul> <li>Integration of object detection neural network with ROS to update SLAM-based global navigation maps</li> <li>Automation of processing scripts to work in real-time with ZED camera video feed</li> <li>Placement of navigation constraints in an occupancy grid </li> </ul>"},{"location":"posts/2019/08/01/accessibility-constraint-mapping/#future-work","title":"Future work","text":"<p>As of writing, this project has many steps to go before realizing the full goal of off-road navigation path planning. First, an extensive training dataset of common off-road navigation constraints (construction sites, stairs, curbs, etc.) should be collected and the YOLO network should be trained to recognize these objects. Then, the new \"constraint\" YOLO network can be integrated into the existing workflow to plot the locations of constraints in a global occupancy grid. Finally, the occupancy grid should be integrated with existing path optimizers to actually produce off-road navigation paths that account for these off-road constraints.</p> <p>A good test for this framework would be Virginia Tech's campus where inadequate support is provided for persons in wheelchairs navigating sidewalks without ADA-compliant curbs.</p>"},{"location":"posts/2020/08/25/neural-networks-for-ultrasonic-defect-detection/","title":"Neural networks for ultrasonic defect detection","text":"<p>An ultrasonic transducer excites a plate-like structure to steady-state and a laser Doppler vibrometer (LDV) scanner obtains the surface velocity response. The wavenumber of the propagating waves is dependent on local changes in thickness of the plate, which indicates damage such as corrosion, cracking, or delamination. This project involved training a convolutional neural network (CNN) on simulated ultrasonic data to classify plate thickness and detect damages and defects. The CNN performed orders of magnitude faster than traditional processing methods and provided more accurate results.</p> <p></p> <p>Fig 1. The Acoustic Steady-State Excitation Spatial Spectroscopy (ASSESS) method.</p>"},{"location":"posts/2020/08/25/neural-networks-for-ultrasonic-defect-detection/#links","title":"Links","text":"<ul> <li>Conference paper \u2014 initial CNN demonstration on ultrasonic data</li> <li>Journal article \u2014 experimental results published in Ultrasonics</li> <li>Code repository \u2014 source code with processing scripts and other documentation</li> </ul>"},{"location":"posts/2020/08/25/neural-networks-for-ultrasonic-defect-detection/#project-overview","title":"Project overview","text":"<p>Fig 2. Overview of the ultrasonic simulation and neural network processing workflow.</p> <ol> <li>Design of metallic plates with varying parameters, including geometry, transducer location, and defect size and shape. Currently only using thin, aluminum plates.</li> <li>Automation of CAD model generation and ANSYS finite-element ultrasonic simulations.</li> <li>Extraction of steady-state surface velocity response and automatic labeling of plate thickness and defect location. The set of ultrasonic wavefield images and their labeled segmentation maps composed the training dataset for the neural network.</li> <li>The training dataset was augmented in size by adding noise and applying transformations.</li> <li>The CNN was trained in <code>PyTorch</code> using the <code>U-net</code> architecture to learn the map between ultrasonic wavefield data and plate thickness.</li> <li>The performance of the CNN was evaluated on a variety of test sets, including experimental ultrasonic data.</li> </ol>"},{"location":"posts/2020/08/25/neural-networks-for-ultrasonic-defect-detection/#project-highlights","title":"Project highlights","text":"<p>We trained the CNN on a fairly regular set of simulations, consisting of regular geometric shapes for defects (i.e. circles, hexagons, etc.) on a 10 mm thick square aluminum plate with a side length of 400 mm. In addition, the structure of the CNN was largely an off-the-shelf model with minimal adjustments from other image processing tasks, such as identifying common objects like animals and furniture.</p> <p>Despite this minimally diverse training set and a rather large number of trainable parameters (\\(\\mathcal{O}(10^6)\\)), the CNN still demonstrated an excellent ability to generalize to unseen ultrasonic data, such as this nested corrosion-like defect:</p> <p></p> <p>Fig 3. CNN prediction on a nested corrosion-like defect on an aluminum plate (Eckels et al 2022).</p> <p>Despite also being trained only on simulated ultrasonic data, the CNN generalized to real experimental ultrasonic data, such as this milled-out scratch on the back of an aluminum plate:</p> <p></p> <p>Fig 4. CNN prediction on experimental ultrasonic data (Eckels et al 2022).</p>"},{"location":"posts/2020/08/25/neural-networks-for-ultrasonic-defect-detection/#contributions","title":"Contributions","text":"<ul> <li>Automation of CAD model generation and ANSYS ultrasonic simulations. Ran my poor laptop into the ground running 3d FEA for many days straight  \u2014 not something an internet-browsing laptop was designed for. I'm glad to report the computer still works even today, but is now retired to internet streaming only.</li> <li>Automation of data processing scripts, including writing scripts in ancient macro languages to extract surface velocity data from ANSYS simulations. Also used clustering to process image segmentation plate thickness labels from raw 3d point cloud data.</li> <li>Tuned off-the-shelf <code>PyTorch</code> models to work with the ultrasonic datasets.</li> </ul>"},{"location":"posts/2020/08/25/neural-networks-for-ultrasonic-defect-detection/#future-work","title":"Future work","text":"<p>To make the system more practical, the training dataset needs to be greatly expanded to include:</p> <ul> <li>thin plates of varying dimension, shape, thickness, and material. Should also use more realistic structures other than just thin plates.</li> <li>various excitation frequencies and transducer simulation parameters. This should improve robustness with respect to variability in real transducer dynamics.</li> <li>a variety of data sources, including different simulation fidelities (i.e. 2d, 3d, grid size) and real experimental measurements, and</li> <li>more realistic defects, including delaminations and thin cracks below the nominal wavelength.</li> </ul> <p>From a high-level, the CNN is essentially learning a map between wavenumbers and material thickness, which is alternatively computed by a Fourier transform and a Lamb-wave dispersion curve. To outperform traditional Fourier methods, the CNN should handle cases where the Fourier transform or Lamb-wave descriptions struggle, such as when the defect size is below the nominal wavelength or near boundaries of the material.</p> <p>It would be interesting to view the latent space (i.e. the \"bottleneck\" of the U-net) learned by the CNN and how it compares to Fourier modes. The current demonstration uses an off-the-shelf model with minimal training to classify plate thickness from a set of discrete numbers; however, this is really a regression problem and we should learn a map between continuous wavenumbers and continuous material thicknesses. This can be accomplished by removing the softmax layer at the end of the network and instead averaging over the probabilities for each thickness prediction.</p>"},{"location":"posts/2018/12/10/bubble-bobble/","title":"Bubble Bobble","text":"<p>Welcome to Bubble Bobble: The Java Mid-Life Crisis of Gaming!</p> <p>Are you a weary traveler on the vast, uncharted plains of the internet, relentlessly searching for something\u2014anything\u2014to stave off the crushing ennui of your existence? Well, my friend, you\u2019ve taken a wrong turn into the back alley of the web, and what\u2019s that lying in a cardboard box? Why, it\u2019s Bubble Bobble, the game no one asked for, brought to you by the coding equivalent of duct tape and prayers!</p> <p></p> <p>Fig 1. One of the hardest levels in the 8-bit arcade classic Bubble Bobble</p> <p>Behold, a marvel of modern mediocrity, lovingly crafted in Java SE 17 (because hey, we like to live dangerously too). From the moment you double-click that .jar file, prepare to be whisked away to a world where audio playback sometimes works and the GUI is as intuitive as your uncle trying to understand TikTok.</p>"},{"location":"posts/2018/12/10/bubble-bobble/#features-you-didnt-know-you-didnt-want","title":"Features You Didn\u2019t Know You Didn\u2019t Want:","text":"<ul> <li>Stunning 2D Graphics: Featuring cutting-edge pixel art that somehow manages to channel the charm of a 90s' clipart collection.</li> <li>Heart-Pounding Audio: When it plays, our hand-picked MIDI tracks will take you right back to the glory days of dial-up internet. Enjoy the nostalgia as your speakers dutifully recreate the sound of your computer struggling to keep up.</li> <li>Engaging Gameplay: Controls that respond almost as quickly as you can press the arrow keys\u2014there's nothing like a slight lag to remind you that life\u2019s all about patience.</li> </ul>"},{"location":"posts/2018/12/10/bubble-bobble/#dont-just-take-our-word-for-it","title":"Don\u2019t Just Take Our Word For It!","text":"<p>Here\u2019s what non-existent critics are saying:</p> <ul> <li>\u201cIt\u2019s... a game? I think?\u201d \u2014 Anonymous</li> <li>\u201cMy cat stepped on the keyboard and kinda enjoyed it. 5/10.\u201d \u2014 Internet Stranger</li> <li>\u201cI laughed, I cried, I wondered why I spent ten minutes downloading this.\u201d \u2014 Unwitting Blog Skimmer</li> </ul>"},{"location":"posts/2018/12/10/bubble-bobble/#how-to-play","title":"How to Play","text":"<ul> <li>Download the JAR: Because nothing says 'safe' like downloading random files from the internet (Github)</li> <li>Run the Game: Double-click the JAR file and cross your fingers. Who needs secure installations?</li> <li>Embrace the Chaos: Navigate through the game using controls that redefine unpredictability.</li> </ul> <p>Despite its many quirks (or perhaps because of them), Bubble Bobble is here to remind you that even in a world of high-definition, meticulously crafted digital experiences, there\u2019s still room for something delightfully... 'handmade'. So, go ahead, take a break from the scroll, and dive into the self-aware silliness of a game that knows just how underwhelming it really is.</p>"},{"location":"posts/2021/05/05/chess-robot/","title":"Chess robot","text":"<p>Introducing: the chess-playing robot that will defeat any opponent who challenges it (mostly because, you know.. Stockfish). The robot is composed of a sleek metal frame and a sturdy acrylic playing surface with a laser-engraved chessboard. A gantry system powered by stepper motors and timing belts moves a claw-like gripper around the board to enact the will of its chess engine AI. Roughly the size of a coffee table and noticeably heavier, this bot is sure to fill out your entire living room with a family-friendly competitive atmosphere.</p> <p></p> <p>Fig 1. The Chess robot in its natural environment (circa 2021).</p>"},{"location":"posts/2021/05/05/chess-robot/#links","title":"Links","text":"<ul> <li>Chessbot demo \u2014 made for the 2021 Rose show</li> <li>Chessbot code \u2014 repository for running the Chess robot</li> </ul>"},{"location":"posts/2021/05/05/chess-robot/#project-highlights","title":"Project highlights","text":"<ul> <li>AI opponent powered by the Stockfish chess engine </li> <li>3d gantry system for moving the piece gripper (design inspired by 3d printers)</li> <li>Arduino microcontroller for motors and sensors</li> <li>Raspberry pi for running the chess engine and controller</li> <li>Display screen for tracking the game state</li> <li>Camera for detecting the game state (and automating the AI opponent's turn)</li> <li>Spiral arm piece gripper with smooth acrylic slots for gripper arms</li> <li>Laser-engraved acrylic chess board</li> <li>Full-size chessboard (which doubles as a coffee table when not in use )</li> </ul> <p>Fig 2. The chess robot gripper (upper left), controller (lower left), and gantry movement system (right).</p>"},{"location":"posts/2021/05/05/chess-robot/#future-work","title":"Future work","text":"<p>Given much more sleek chess bots available online, I'd like to revisit this project at some point and turn it into a buildable toy kit. I still like the gantry system idea, but it does make it hard to access the pieces. It's also way too big for the average child (or adult for that matter -- but you should've seen the first version of this bot, which had to be disassembled to even take it out of the room it was built in ). So perhaps we shrink the size and simplify the number of moving components. </p> <p>I also like the spiral arm gripper, but it's not very consistent. Maybe need to replace the claw design with an easier magnetic-based design. It would also be cool to have an AI opponent that learns to play like you and challenges your weak points to improve your play.</p>"},{"location":"posts/2022/12/28/electrospray-thruster-design/","title":"Electrospray thruster design","text":"<p>Electrospray thrusters produce thrust by extracting and accelerating liquid ionic droplets from a porous substrate using a strong applied electric field. The task of scaling electrospray thrusters to missions with higher thrust requirements is one of seeking robust designs in the presence of high manufacturing uncertainties in the extractor grid and porous substrate. This project explored Bayesian methods for aiding electrospray thruster design in light of these manufacturing uncertainties.</p> <p></p> <p>Fig 1. The AFET-2 electrospray thruster (Natisan et al. 2020).</p>"},{"location":"posts/2022/12/28/electrospray-thruster-design/#links","title":"Links","text":"<ul> <li>Spectral sciences \u2014 ElectroSpray Propulsion Toolkit (ESPET)</li> <li>IEPC paper \u2014 design space exploration using a neural network</li> <li>SciTech paper \u2014 optimal experimental design (OED) for model calibration</li> <li>Matlab PDE code \u2014 electrostatic simulations of electrospray emitters</li> <li>Bayesian OED code \u2014 experimental design  results</li> <li>Simulation database \u2014 around 50,000 electrostatic simulation results</li> </ul>"},{"location":"posts/2022/12/28/electrospray-thruster-design/#project-goals","title":"Project goals","text":"<ul> <li>Explore the electrospray design space using a neural network surrogate.</li> <li>Apply optimal experimental design (OED) for calibrating an electrospray current emission model.</li> </ul> <p>Fig 2. Electrospray array current emission model.</p>"},{"location":"posts/2022/12/28/electrospray-thruster-design/#contributions","title":"Contributions","text":"<ul> <li>Dec 2021 \u2014 Automated a Matlab PDE solver for varying electrospray emitter geometries to obtain peak electrostatic field (a key quantity of interest for design).</li> <li>June 2022 \u2014 Trained a neural network to learn the electrostatic field as a function of geometry. Used the neural network for sensitivity analysis and design space exploration.</li> <li>Dec 2022 \u2014 Implemented and compared three methods for Bayesian OED.</li> <li>Jan 2023 \u2014 Applied OED to calibrate the electrospray current emission model (Fig 2).</li> </ul> <p>Further details can be found in the linked conference papers.</p>"},{"location":"posts/2024/09/27/predictive-hall-thruster-modeling/","title":"Predictive Hall thruster modeling","text":"<p>Hall thrusters are a form of in-space electric propulsion in which a plasma discharge is maintained using crossed electric and magnetic (i.e. \\(\\mathbf{E}\\times \\mathbf{B}\\)) fields. Hall thrusters have exploded in popularity in recent years due to their high efficiency and low cost. One of the primary challenges in Hall thruster development is accurately modeling the discharge plasma, especially with respect to the poorly understood physics of electron transport and the coupling of the thruster to its testing environment. These and other related issues introduce large uncertainties to model predictions and prevent the applicability of ground-test data to in-space operation. The ongoing work of the JANUS institute is to develop a predictive model of the Hall thruster operating in a vacuum chamber and to reliably make confidence-bounded estimates of in-space performance.</p> <p></p> <p>Fig 1. The predictive Hall thruster modeling framework (Eckels et al. 2024).</p>"},{"location":"posts/2024/09/27/predictive-hall-thruster-modeling/#links","title":"Links","text":"<ul> <li>Journal article \u2014 outlining the predictive modeling and uncertainty quantification framework</li> <li><code>hallmd</code> code \u2014 repository for the Hall thruster modeling and analysis tools</li> </ul>"},{"location":"posts/2024/09/27/predictive-hall-thruster-modeling/#project-goals","title":"Project goals","text":"<ul> <li>Couple models of the Hall thruster discharge plasma to the test facility.</li> <li>Calibrate the models to experimental data through Bayesian inference.</li> <li>Perform sensitivity analysis to determine most important aspects of the model.</li> <li>Validate models on ground-test data and extrapolate predictions to the in-space environment.</li> <li>Assess confidence in predictions through uncertainty quantification.</li> <li>Perform experimental design to gather influential data for reducing model uncertainty.</li> </ul>"},{"location":"posts/2024/09/27/predictive-hall-thruster-modeling/#current-status","title":"Current status","text":"<p>This is an ongoing research project within the JANUS institute. Our most recent results are reported in the Journal of Electric Propulsion (see linked article above). We have calibrated a simple cathode-thruster-plume feedforward model on data for the SPT-100 thruster and reduced uncertainty from the prior distributions. However, our model still shows significant discrepancy with experimental data, including in the extrapolation regions. See for example our predictions of discharge current (copied from the journal article):</p> <p></p> <p>Fig 2. Improvement in predictions of discharge current from the prior to the posterior (Eckels et al. 2024).</p> <p>We have made several suggestions for improving the model, including revisions to the anomalous transport closure and the coupling between the discharge channel and the plume. We also hope to link a new downstream model for predicting carbon sputter in the vacuum chamber.</p>"},{"location":"posts/2024/09/27/predictive-hall-thruster-modeling/#contributions","title":"Contributions","text":"<ul> <li>Dec 2022 \u2014 implemented the first version of the multidisciplinary coupled model and ran an initial Monte Carlo analysis on epistemic sources of uncertainty (i.e. the fit coefficients).</li> <li>May 2023 \u2014 implemented an adaptive, multi-fidelity, multidisciplinary surrogate building framework see <code>amisc</code>.</li> <li>August 2023 \u2014 automated the surrogate-building infrastructure and applied it to the coupled Hall thruster model.</li> <li>December 2023 \u2014 first release of the <code>hallmd</code> code repository, which provides an API for extending models and the testing framework.</li> <li>May 2024 \u2014 completed the uncertainty quantification analysis of the Hall thruster model, including Bayesian inference, sensitivity analysis, and Monte Carlo.</li> <li>September 2024 \u2014 published the first set of results in the Journal of Electric Propulsion.</li> </ul> <p>Further details can be found in the linked journal article.</p>"},{"location":"posts/2021/07/31/high-voltage-battery-firmware/","title":"High-voltage battery firmware","text":"<p>As part of a summer internship at Tesla on the battery firmware subteam, a series of upgrades to the battery testing infrastructure were underway. A new suite of tests were being developed for the newest Model 3 and semi-truck battery packs. The battery firmware is responsible for interfacing with the vehicle CAN networks, including intercepting and responding to messages involved with charging and discharging the battery, as well as monitoring the battery's state of charge, temperature, performance, and long-term health. Testing the battery firmware involves simulating the vehicle CAN signals to run repeated cycles of charging and discharging, and to purposely fault the system to ensure proper shutdown and recovery.</p> <p></p> <p>Fig 1. A high-voltage electric vehicle (EV) battery on a testing stand.</p>"},{"location":"posts/2021/07/31/high-voltage-battery-firmware/#project-goals","title":"Project goals","text":"<p>The primary goal of my internship was to automate large portions of the battery firmware testing framework in Python, as well as to assist in running battery tests for the newest line of vehicles.</p>"},{"location":"posts/2021/07/31/high-voltage-battery-firmware/#contributions","title":"Contributions","text":"<ul> <li>Upgraded 3 (out of 6) battery pack testing hardware units to the newest PCAN interface.</li> <li>Automated all state-of-charge firmware tests in the <code>pytest</code> framework, using a remote <code>Jenkins</code> workflow to trigger sequential regression tests and the collection of CAN traces for determining battery performance.</li> <li>Designed and implemented a software abstraction for high-voltage switchbox controllers, allowing multiple vehicle platforms (i.e. Model 3, Model X, etc.) to run on the same testing framework.</li> <li>Contributed to various other firmware projects by reviewing pull requests and debugging both hardware and software issues (including a communication issue with the chiller that caused the batteries to periodically overheat during testing ).</li> </ul>"},{"location":"posts/archive/2024/","title":"2024","text":""},{"location":"posts/archive/2022/","title":"2022","text":""},{"location":"posts/archive/2021/","title":"2021","text":""},{"location":"posts/archive/2020/","title":"2020","text":""},{"location":"posts/archive/2019/","title":"2019","text":""},{"location":"posts/archive/2018/","title":"2018","text":""},{"location":"posts/category/projects/","title":"Projects","text":""}]}